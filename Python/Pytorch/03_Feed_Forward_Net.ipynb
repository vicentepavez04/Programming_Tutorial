{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feed_Forward_Net.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C-kSTa5bcwzc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "X-TdeZg-c0Y7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameters\n",
        "\n",
        "input_size = 784  # 28x28\n",
        "hidden_size = 110 \n",
        "num_classes = 10  # 0-9 digists\n",
        "num_epochs = 10\n",
        "batch_size = 100\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "KER-nVrNc0bz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MNIST DATA\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                           transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                           transform=transforms.ToTensor())"
      ],
      "metadata": {
        "id": "G7VkdUbdc0eZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "train_loader = torch.utils.data.DataLoader(dataset= train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "examples = iter(train_loader)\n",
        "samples, labels = examples.next()\n",
        "print(samples.shape, labels.shape)\n",
        "\n",
        "#[samples(batch), channel(1 grayscale image), image_size] ([nÂ°labels])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_UL3BRZu9K7",
        "outputId": "18a15649-ff21-4c94-e480-5300f0a54e0a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data visualization\n",
        "\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3, i+1)\n",
        "  plt.imshow(samples[i][0], cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "DWDbxynavvv0",
        "outputId": "94a14623-7fae-4b73-ee46-c6a50c17c178"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Network\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    self.l1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.l1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.l2(out)\n",
        "    # Multiclassification problem dont need activacion function at the end,\n",
        "    # because we use CrossEntropy loss, the loss applies the softmax function automatically.\n",
        "    return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)"
      ],
      "metadata": {
        "id": "_24hIvj7wkVB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loss and optimizer\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "jVbLDZwQwxBS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Loop\n",
        "n_total_steps = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    # 100, 1 , 28, 28\n",
        "    # 100, 784\n",
        "    #reshape tensor\n",
        "    images = images.reshape(-1, 28*28).to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # Forward\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    #backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1) % 100 == 0:\n",
        "      print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps}, loss= {loss.item():.4f}')\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfcPRKRUwxDi",
        "outputId": "be24a31b-2661-401d-abf8-e36d08018cca"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1/10, step 100/600, loss= 0.4591\n",
            "epoch 1/10, step 200/600, loss= 0.3148\n",
            "epoch 1/10, step 300/600, loss= 0.3902\n",
            "epoch 1/10, step 400/600, loss= 0.3187\n",
            "epoch 1/10, step 500/600, loss= 0.3034\n",
            "epoch 1/10, step 600/600, loss= 0.3375\n",
            "epoch 2/10, step 100/600, loss= 0.0836\n",
            "epoch 2/10, step 200/600, loss= 0.2105\n",
            "epoch 2/10, step 300/600, loss= 0.1470\n",
            "epoch 2/10, step 400/600, loss= 0.1022\n",
            "epoch 2/10, step 500/600, loss= 0.1129\n",
            "epoch 2/10, step 600/600, loss= 0.1156\n",
            "epoch 3/10, step 100/600, loss= 0.1457\n",
            "epoch 3/10, step 200/600, loss= 0.1183\n",
            "epoch 3/10, step 300/600, loss= 0.2356\n",
            "epoch 3/10, step 400/600, loss= 0.2030\n",
            "epoch 3/10, step 500/600, loss= 0.0693\n",
            "epoch 3/10, step 600/600, loss= 0.0938\n",
            "epoch 4/10, step 100/600, loss= 0.0857\n",
            "epoch 4/10, step 200/600, loss= 0.0807\n",
            "epoch 4/10, step 300/600, loss= 0.1177\n",
            "epoch 4/10, step 400/600, loss= 0.0627\n",
            "epoch 4/10, step 500/600, loss= 0.1904\n",
            "epoch 4/10, step 600/600, loss= 0.0519\n",
            "epoch 5/10, step 100/600, loss= 0.0699\n",
            "epoch 5/10, step 200/600, loss= 0.1159\n",
            "epoch 5/10, step 300/600, loss= 0.0992\n",
            "epoch 5/10, step 400/600, loss= 0.0837\n",
            "epoch 5/10, step 500/600, loss= 0.0550\n",
            "epoch 5/10, step 600/600, loss= 0.0539\n",
            "epoch 6/10, step 100/600, loss= 0.1106\n",
            "epoch 6/10, step 200/600, loss= 0.0892\n",
            "epoch 6/10, step 300/600, loss= 0.0628\n",
            "epoch 6/10, step 400/600, loss= 0.0255\n",
            "epoch 6/10, step 500/600, loss= 0.0496\n",
            "epoch 6/10, step 600/600, loss= 0.0887\n",
            "epoch 7/10, step 100/600, loss= 0.0257\n",
            "epoch 7/10, step 200/600, loss= 0.0402\n",
            "epoch 7/10, step 300/600, loss= 0.0945\n",
            "epoch 7/10, step 400/600, loss= 0.0693\n",
            "epoch 7/10, step 500/600, loss= 0.0572\n",
            "epoch 7/10, step 600/600, loss= 0.0755\n",
            "epoch 8/10, step 100/600, loss= 0.0224\n",
            "epoch 8/10, step 200/600, loss= 0.0940\n",
            "epoch 8/10, step 300/600, loss= 0.0381\n",
            "epoch 8/10, step 400/600, loss= 0.0433\n",
            "epoch 8/10, step 500/600, loss= 0.0194\n",
            "epoch 8/10, step 600/600, loss= 0.0294\n",
            "epoch 9/10, step 100/600, loss= 0.0228\n",
            "epoch 9/10, step 200/600, loss= 0.0270\n",
            "epoch 9/10, step 300/600, loss= 0.0907\n",
            "epoch 9/10, step 400/600, loss= 0.0269\n",
            "epoch 9/10, step 500/600, loss= 0.0365\n",
            "epoch 9/10, step 600/600, loss= 0.0496\n",
            "epoch 10/10, step 100/600, loss= 0.0212\n",
            "epoch 10/10, step 200/600, loss= 0.0627\n",
            "epoch 10/10, step 300/600, loss= 0.0638\n",
            "epoch 10/10, step 400/600, loss= 0.0232\n",
            "epoch 10/10, step 500/600, loss= 0.0229\n",
            "epoch 10/10, step 600/600, loss= 0.0317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "\n",
        "with torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = 0\n",
        "  for images, labels in test_loader:\n",
        "    images = images.reshape(-1,28*28).to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "\n",
        "    # return the value and index (index = predictions)\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "    n_samples += labels.shape[0]\n",
        "    n_correct += (predictions == labels).sum().item()\n",
        "\n",
        "  accuracy = 100.0 * n_correct / n_samples\n",
        "  print(f'accuracy = {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnthpzS-wxGQ",
        "outputId": "1f564d66-b0c2-4585-cf1a-89e9f90a9051"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy = 97.68\n"
          ]
        }
      ]
    }
  ]
}
